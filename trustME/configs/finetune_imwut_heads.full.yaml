# Full training profile for trustME/source/finetune_imwut_heads.py
# Purpose: primary run on the full (post-filtered) IMWUT processed dataset.

input_dir: trustME/data/processed/imwut_tobii
raw_root: trustME/data/raw/imwut
seg_csv: null
rebuild_inputs: false

schemes:
  # - binary
  # - edr
  - avm
head_types:
  # - linear
  - mlp

model_name: AutonLab/MOMENT-1-large
batch_size: 64
epochs: 10
patience: 3
lr: 0.0001
weight_decay: 0.0001
seed: 42
device: auto
num_workers: 4
clear_cuda_cache_between_heads: true
save_model: false
save_metrics: true
save_base_embeddings: true
save_head_features: true

subject_train_frac: 0.70
subject_val_frac: 0.15
subject_test_frac: 0.15

mlp_hidden_dim: 256
mlp_dropout: 0.1

# Optional speed-up:
# - null or >=1.0 means use all rows for each scheme.
# - (0,1) means stratified random subset per scheme.
subset_fraction: 0.5
subset_min_per_class: 1
subset_seed: 42

drop_central_and_questionnaire: true
verbose: false

out_dir: trustME/data/processed/imwut_tobii_finetuned
